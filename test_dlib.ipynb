{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import yaml\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from backbone.repvgg import get_RepVGG_func_by_name\n",
    "import utils\n",
    "\n",
    "class SixDRepNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 backbone_name, backbone_file, deploy,\n",
    "                 bins=(1, 2, 3, 6),\n",
    "                 droBatchNorm=nn.BatchNorm2d,\n",
    "                 pretrained=True):\n",
    "        super(SixDRepNet, self).__init__()\n",
    "\n",
    "        repvgg_fn = get_RepVGG_func_by_name(backbone_name)\n",
    "        backbone = repvgg_fn(deploy)\n",
    "        if pretrained:\n",
    "            checkpoint = torch.load(backbone_file)\n",
    "            if 'state_dict' in checkpoint:\n",
    "                checkpoint = checkpoint['state_dict']\n",
    "            ckpt = {k.replace('module.', ''): v for k,\n",
    "                    v in checkpoint.items()}  # strip the names\n",
    "            backbone.load_state_dict(ckpt)\n",
    "\n",
    "        self.layer0, self.layer1, self.layer2, self.layer3, self.layer4 = backbone.stage0, backbone.stage1, backbone.stage2, backbone.stage3, backbone.stage4\n",
    "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "\n",
    "        last_channel = 0\n",
    "        for n, m in self.layer4.named_modules():\n",
    "            if ('rbr_dense' in n or 'rbr_reparam' in n) and isinstance(m, nn.Conv2d):\n",
    "                last_channel = m.out_channels\n",
    "\n",
    "        fea_dim = last_channel\n",
    "\n",
    "        self.linear_reg = nn.Linear(fea_dim, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x= self.gap(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear_reg(x)\n",
    "        return utils.compute_rotation_matrix_from_ortho6d(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SixDRepNet(\n",
       "  (layer0): RepVGGBlock(\n",
       "    (nonlinearity): ReLU()\n",
       "    (se): Identity()\n",
       "    (rbr_reparam): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (1): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (2): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (1): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (2): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (4): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (5): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (1): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (2): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (4): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (5): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (6): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (7): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (8): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (9): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (10): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (11): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (12): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (13): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (14): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (15): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (gap): AdaptiveAvgPool2d(output_size=1)\n",
       "  (linear_reg): Linear(in_features=2048, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"HEAD_POSE_MODEL.pt\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SixDRepNet(\n",
       "  (layer0): RepVGGBlock(\n",
       "    (nonlinearity): ReLU()\n",
       "    (se): Identity()\n",
       "    (rbr_reparam): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (1): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (2): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (1): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (2): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (4): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (5): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (1): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (2): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (4): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (5): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (6): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (7): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (8): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (9): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (10): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (11): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (12): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (13): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (14): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (15): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (gap): AdaptiveAvgPool2d(output_size=1)\n",
       "  (linear_reg): Linear(in_features=2048, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SixDRepNet(backbone_name='RepVGG-B1g2',\n",
    "                    backbone_file='',\n",
    "                    deploy=True,\n",
    "                    pretrained=False)\n",
    "saved_state_dict = torch.load(\"6DRepNet_300W_LP_BIWI.pth\")\n",
    "if 'model_state_dict' in saved_state_dict:\n",
    "    model.load_state_dict(saved_state_dict['model_state_dict'])\n",
    "else:\n",
    "    model.load_state_dict(saved_state_dict)\n",
    "\n",
    "model.eval()\n",
    "model.cuda()\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFile = \"res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "configFile = \"deploy.prototxt\"\n",
    "net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "# landmark_detector = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.loader.FullLoader)\n",
    "video = cv2.VideoCapture(\"images/NTHUDDD_dataset/Training_Evaluation_Dataset/Training Dataset/036/noglasses/nonsleepyCombination.avi\")\n",
    "valid, img = video.read()\n",
    "for i in range(0, 395):\n",
    "    valid, img = video.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN FACE DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200, 52, 371, 328]\n"
     ]
    }
   ],
   "source": [
    "h, w = img.shape[:2]\n",
    "blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0,\n",
    "(300, 300), (104.0, 117.0, 123.0))\n",
    "net.setInput(blob)\n",
    "faces = net.forward()\n",
    "#to draw faces on image\n",
    "drawn_image_dnn = img.copy()\n",
    "faces_dnn = []\n",
    "factor = 0.2\n",
    "bestBox = ()\n",
    "for i in range(faces.shape[2]):\n",
    "    confidence = faces[0, 0, i, 2]\n",
    "    if confidence > 0.5:\n",
    "        box = faces[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (x, y, x1, y1) = box.astype(\"int\")\n",
    "        width = abs(x1 - x)\n",
    "        height = abs(y1 - y)\n",
    "        minX = max(0, int(x) - int(factor*width))\n",
    "        minY = max(0, int(y) - int(factor*height))\n",
    "        maxX = int(x1) + int(factor*width)\n",
    "        maxY = int(y1) + int(factor*height)\n",
    "        bestBox = [minX, minY, maxX, maxY]\n",
    "        print(bestBox)\n",
    "        faces_dnn.append(bestBox)\n",
    "        # drawn_image_dnn = cv2.rectangle(drawn_image_dnn, (x, y), (x1, y1), (0, 0, 255), 2)\n",
    "\n",
    "(x, y, x1, y1) = bestBox\n",
    "face_img = drawn_image_dnn[y:y1, x:x1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([transforms.Resize(224),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[291, 126, 524, 445]\n",
      "Head pose estimation: 666.033745 ms\n",
      "(tensor([-17.6814], grad_fn=<CopyBackwards>), tensor([2.9073], grad_fn=<CopyBackwards>), tensor([-3.5567], grad_fn=<CopyBackwards>))\n",
      "[287, 104, 506, 421]\n",
      "Head pose estimation: 42.999744 ms\n",
      "(tensor([-8.4753], grad_fn=<CopyBackwards>), tensor([5.1045], grad_fn=<CopyBackwards>), tensor([-4.0752], grad_fn=<CopyBackwards>))\n",
      "[279, 106, 498, 422]\n",
      "Head pose estimation: 32.000542 ms\n",
      "(tensor([-9.0314], grad_fn=<CopyBackwards>), tensor([18.9989], grad_fn=<CopyBackwards>), tensor([-3.3609], grad_fn=<CopyBackwards>))\n",
      "[233, 116, 460, 407]\n",
      "Head pose estimation: 32.000065 ms\n",
      "(tensor([0.8258], grad_fn=<CopyBackwards>), tensor([70.5785], grad_fn=<CopyBackwards>), tensor([11.8135], grad_fn=<CopyBackwards>))\n",
      "[173, 157, 413, 440]\n",
      "Head pose estimation: 202.997684 ms\n",
      "(tensor([-13.5300], grad_fn=<CopyBackwards>), tensor([13.0091], grad_fn=<CopyBackwards>), tensor([-34.9199], grad_fn=<CopyBackwards>))\n",
      "[245, 123, 469, 438]\n",
      "Head pose estimation: 195.021629 ms\n",
      "(tensor([-13.4467], grad_fn=<CopyBackwards>), tensor([5.0673], grad_fn=<CopyBackwards>), tensor([-7.8082], grad_fn=<CopyBackwards>))\n",
      "[243, 124, 462, 434]\n",
      "Head pose estimation: 64.998865 ms\n",
      "(tensor([-12.3198], grad_fn=<CopyBackwards>), tensor([6.3432], grad_fn=<CopyBackwards>), tensor([-8.4653], grad_fn=<CopyBackwards>))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\TFG\\MVP\\test_dlib.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/TFG/MVP/test_dlib.ipynb#ch0000010?line=54'>55</a>\u001b[0m utils\u001b[39m.\u001b[39mplot_pose_cube(frame,  y_pred_deg, p_pred_deg, r_pred_deg, x \u001b[39m+\u001b[39m \u001b[39mint\u001b[39m(\u001b[39m.5\u001b[39m\u001b[39m*\u001b[39m(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/TFG/MVP/test_dlib.ipynb#ch0000010?line=55'>56</a>\u001b[0m     x1\u001b[39m-\u001b[39mx)), y \u001b[39m+\u001b[39m \u001b[39mint\u001b[39m(\u001b[39m.5\u001b[39m\u001b[39m*\u001b[39m(y1\u001b[39m-\u001b[39my)), size\u001b[39m=\u001b[39mx1\u001b[39m-\u001b[39mx)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/TFG/MVP/test_dlib.ipynb#ch0000010?line=57'>58</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, frame)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/TFG/MVP/test_dlib.ipynb#ch0000010?line=58'>59</a>\u001b[0m cv2\u001b[39m.\u001b[39;49mwaitKey()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0,\n",
    "    (300, 300), (104.0, 117.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    faces = net.forward()\n",
    "    #to draw faces on image\n",
    "    drawn_image_dnn = frame.copy()\n",
    "    faces_dnn = []\n",
    "    factor = 0.2\n",
    "    bestBox = ()\n",
    "    for i in range(faces.shape[2]):\n",
    "        confidence = faces[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            box = faces[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (x, y, x1, y1) = box.astype(\"int\")\n",
    "            width = abs(x1 - x)\n",
    "            height = abs(y1 - y)\n",
    "            minX = max(0, int(x) - int(factor*width))\n",
    "            minY = max(0, int(y) - int(factor*height))\n",
    "            maxX = int(x1) + int(factor*width)\n",
    "            maxY = int(y1) + int(factor*height)\n",
    "            bestBox = [minX, minY, maxX, maxY]\n",
    "            print(bestBox)\n",
    "            faces_dnn.append(bestBox)\n",
    "            # drawn_image_dnn = cv2.rectangle(drawn_image_dnn, (x, y), (x1, y1), (0, 0, 255), 2)\n",
    "\n",
    "    (x, y, x1, y1) = bestBox\n",
    "    face_img = drawn_image_dnn[y:y1, x:x1]\n",
    "\n",
    "\n",
    "def estimate_head_pose_model(face_img, facebox):\n",
    "    img = Image.fromarray(face_img)\n",
    "    img = img.convert('RGB')\n",
    "    img = transformations(img)\n",
    "\n",
    "    img = torch.Tensor(img[None, :]).cuda(0)\n",
    "\n",
    "    start = time.time()\n",
    "    R_pred = model(img)\n",
    "    end = time.time()\n",
    "\n",
    "    euler = utils.compute_euler_angles_from_rotation_matrices(\n",
    "        R_pred)*180/np.pi\n",
    "    pitch = euler[:, 0].cpu()\n",
    "    yaw = euler[:, 1].cpu()\n",
    "    roll = euler[:, 2].cpu()\n",
    "\n",
    "    return {\"yaw\": yaw, \"pitch\": pitch, \"roll\": roll}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"HEAD_POSE_MODEL.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DLIB FACE DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "rectangles[[(167, 116) (322, 270)]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# faces_dlib = face_detector(img, 1)\n",
    "# print(len(faces_dlib))\n",
    "# print(faces_dlib)\n",
    "# x = faces_dlib[0].left()\n",
    "# y = faces_dlib[0].top()\n",
    "# x1 = faces_dlib[0].right()\n",
    "# y1 = faces_dlib[0].bottom()\n",
    "# w = x1 - x\n",
    "# h = y1 - y\n",
    "\n",
    "# drawn_image = img.copy()\n",
    "# drawn_image = cv2.rectangle(drawn_image, (x, y), (x1, y1), (0, 0, 255), 2)\n",
    "# cv2.imshow(\"\", drawn_image)\n",
    "# cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# landmark_tuple = []\n",
    "# img_copy = img.copy()\n",
    "# for k, d in enumerate(faces_dlib):\n",
    "#    # rect = dlib.rectangle(*d)\n",
    "#    landmarks = landmark_detector(img, d)\n",
    "#    for n in range(0, 68):\n",
    "#       x = landmarks.part(n).x\n",
    "#       y = landmarks.part(n).y\n",
    "#       landmark_tuple.append((x, y))\n",
    "#       cv2.circle(img_copy, (x, y), 1, (255, 255, 0), -1)\n",
    "\n",
    "# cv2.imshow(' ', img_copy)\n",
    "# cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2fbddd60e78eb538571104c333f920842b70854f7bd7da5c83068516aff2b99"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dlib')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
